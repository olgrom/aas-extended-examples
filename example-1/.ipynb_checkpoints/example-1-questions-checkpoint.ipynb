{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flipping coins with Professor Mittens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline and housekeeping\n",
    "\n",
    "The material in this notebook covers four topics: binomial distributions, the central limit theorem, outliers in data and invalid model assumptions. _You will have approximately 15 minutes to work through each part, after which we will go through the answers together._ Exercises marked as \"extension\" may be more challenging, so you can skip them on a first reading if you feel they will take too much time.\n",
    "\n",
    "This notebook is available on github [here](https://github.com/aezarebski/aas-extended-examples). If you find errors or would like to suggest an improvement, feel free to create an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab we will look at the binomial distribution, central limit theorem, and analyse two data sets collected by [Professor Mittens](https://en.wikipedia.org/wiki/Mittens_(cat)) helping him interrogate the bais in the results of coin flips. Some of the questions are open-ended by design. Partial solutions will be distributed at the end of the session. The imports below are used in the provided solutions, consider these suggestions, not constraints. The answers use `altair` but you can use any plotting library you are comfortable with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import altair as alt\n",
    "from typing import List, Any, Tuple\n",
    "from functools import reduce\n",
    "from itertools import repeat\n",
    "import math as math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter estimation of the binomial distribution\n",
    "\n",
    "Bernoulli and binomial random variables are the typical way to represent the outcome of coin flips. Below we consider estimates of the probability of heads based on a known number of successes in a given number of trials and also a confidence interval (CI) for this based on the Wald method will be given.\n",
    "\n",
    "Let $X$ be a binomial random variable (RV) which results from the number of heads when a coin is flipped $n$ times and the probability of coming up heads is $p$. For the time being we will assume that $n$ is know. The expected value of $X$ is $np$. So a simple way to estimate $p$ is to divide the number of heads, $X$, by the number of flips, $n$. This gives the estimate \n",
    "\n",
    "$$\n",
    "\\hat{p} = X / n.\n",
    "$$\n",
    "\n",
    "It turns out that this is a very sensible thing to do. The resulting estimate is called the maximum likelihood estimate (MLE) of $p$. It is also the result that one obtains via [the method of moments](https://en.wikipedia.org/wiki/Method_of_moments_(statistics)).\n",
    "\n",
    "Given an estimator though, we want to know how confident we are in the estimate it produces. Here we will use the Wald method to get the $95\\%$ CI. It is a very simple method but is acceptable when we have a fair bit of data. The estimated standard error of $\\hat{p}$ is $\\sqrt{\\hat{p}(1-\\hat{p})/n}$, so the Wald CI is given by\n",
    "\n",
    "$$\n",
    "\\hat{p} \\pm z \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n",
    "$$\n",
    "\n",
    "where $z$ is the appropriate quantile of the standard normal distribution. In the case of a $95\\%$ distribution this is just $1.96$.\n",
    "\n",
    "This is stated on the [wikipedia](https://en.wikipedia.org/wiki/Binomial_distribution#Estimation_of_parameters) but there is also a reasonably clear description in [All of Statistics](https://link.springer.com/book/10.1007/978-0-387-21736-9) which you can get via SOLO. You can also find reasonable treatments of Wald CIs in both of those resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 part I\n",
    "\n",
    "Professor Mittens is not very familiar with the binomial distribution and wants you to justify the estimator used above. Convince yourself that the estimate given above, $X/n$, is a sensible choice. Prove that it is either the MLE or the method of moments estimator for $p$. State the limitations on the estimator we are using for the CI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "What is the motivation behind MoM? \n",
    "The moments of a distribution (if you get all the moments), that uniquely defines a distribution. We are using population parameters to assemble missing pieces of sample distribution...\n",
    "\n",
    "*Method of moments*: take the expected value of distribution = sample average. Solve for parameter of interest:\n",
    "\n",
    "Given $n$ we know that $X\\sim Bin(n,p)$\n",
    "We know that $EX = n p$\n",
    "MoM says estimate p by:\n",
    "\n",
    "$\\hat{X}$ = sample estimate. \n",
    "\n",
    "$\\bar{X}$ = sample average\n",
    "\n",
    "$\\hat{X} = p n$ Solve for $p$ gives us the estimate that $p = \\bar{X}/n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 part II\n",
    "\n",
    "Implement a function called `wald_estimate_and_ci` which takes two arguments: `num_trials` which is $n$ in the description above, and `num_success` which is $X$ above. The function should return `(p_hat,(wald_lower,wald_upper))` where `p_hat` is $\\hat{p}$ and `wald_x` are the limits on the $95\\%$ CI using the Wald method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI = Tuple[float, float]\n",
    "EstimateAndCI = Tuple[float, CI]\n",
    "\n",
    "def wald_estimate_and_ci(num_trials: int, num_success: int) -> EstimateAndCI:\n",
    "    p_hat = num_success / num_trials\n",
    "    z = 1.96\n",
    "    delta = z * math.sqrt(p_hat * (1-p_hat) / num_trials)\n",
    "    return (p_hat, (p_hat - delta, p_hat + delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 part I\n",
    "\n",
    "Look up how to simulate a random variable from a binomial distribution (it tells you [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html#scipy.stats.binom) if you want to use `scipy`). Then simulate a binomial random variable with $n=100$ and $p=0.6$. Then use the value and the `wald_estimate_and_ci` function to see how well you can estimate $p$. Write a couple of sentences to explain this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5, (0.19009678930349883, 0.8099032106965012))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "print(wald_estimate_and_ci(10, 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 part II\n",
    "\n",
    "Repeat the process about 100000 times and see what proportion of the CIs capture the true value of $p$. Is it what you expect? Write a couple of sentences to explain what you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94791"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv = binom.rvs(100, 0.6, size = 100000)\n",
    "\n",
    "def ci_contains_value(ci:CI, p:float) -> bool:\n",
    "    lower, upper = ci\n",
    "    return lower < p and p <upper\n",
    "\n",
    "p_in_ci_bools= [ci_contains_value(wald_estimate_and_ci(100, x)[1], 0.6) for x in rv]\n",
    "reduce(lambda a, b: a + 1 if b else a, p_in_ci_bools, 0) / 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 part III\n",
    "\n",
    "Are credible intervals and confidence intervals the same thing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central limit theorem\n",
    "\n",
    "The central limit theorem tells us about the limiting distribution of the sample mean for distribution for an IID [INDEPENDENTLY AND IDENTICALLY DRAWN] sample with a finite variance. It underpins many results in statistics and is important for reasoning about stochastic processes.\n",
    "\n",
    "### Exercise 3 part I (Extension)\n",
    "\n",
    "Professor Mittens *really* likes to sound fancy and use the name of important theorems. Write down a statement of the law of large numbers. Write down a statement of the central limit theorem. Make sure you understand what each of them tells you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Law of Large Numbers** As the sample size grows, the sample mean becomes closer to that of the popultaion. \n",
    "\n",
    "As n goes to infinity\n",
    "\n",
    "**Central Limit Theorem** Distirbution of sample means will be normally distributed at the limit if you take sufficiently large samples from the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 part II\n",
    "\n",
    "To see that the distribution of the sample mean converges to a normal distribution we will do a simulation study and compare the results with a Q-Q plot to see if it looks normally distributed. This will also demonstrate how to construct a Q-Q plot from first principles, not that you really want to do that. Carry out the following steps:\n",
    "\n",
    "1. Write down the distribution of the sample mean given an IID sample of exponential random variables with rate $1/5$.\n",
    "2. Generate 500 sample means each based on a sample of 100 exponential random variables\n",
    "3. Make a visualisation of the distribution of the data (e.g., a KDE or histogram) and overlay the CLT approximation.\n",
    "4. Make a Q-Q plot to see if the sample means do appear to follow a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 : ~ 5\n",
    "# \n",
    "sample_size = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental results: flipping coins in series\n",
    "\n",
    "Professor Mittens asked 15 of his students to each take turns flipping a coin 30 times and recording how many heads they got. He has a sneaking suspicion that some of the students did not actually do this properly, that they just wrote down some garbage and went to lunch early. We will help Mittens work out whether the coin that was used was fair, i.e. has an equal chance of showing heads or tails.\n",
    "\n",
    "### Exercise 3 part I\n",
    "\n",
    "Read the data in `experiement1.csv` into a `DataFrame`. Use some of the commands you've seen in lectures to inspect the data, noting that it may not be in the optimal format for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1_df = pd.read_csv('experiment1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 part II\n",
    "\n",
    "Compute the point estimate and CI using the function you wrote above. Write a sentence explaining whether you think the coin is a _fair_ coin given the results you have just obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.49333333333333335, (0.44713979693549655, 0.5395268697311701))\n"
     ]
    }
   ],
   "source": [
    "head_counts = exp1_df.drop(columns=\"flip_number\").groupby(\"name\").sum()\n",
    "head_counts[\"name\"] = head_counts.index.copy()\n",
    "\n",
    "total_heads = int(head_counts[\"outcome\"].sum())\n",
    "num_people = int(head_counts[\"name\"].unique().size)\n",
    "num_flips = int(exp1_df[\"name\"].value_counts().unique())\n",
    "\n",
    "est_and_ci = wald_estimate_and_ci(num_success=total_heads, \n",
    "                                  num_trials=num_people * num_flips)\n",
    "\n",
    "print(est_and_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      outcome  name\n",
       "name               \n",
       "0           9     0\n",
       "1          13     1\n",
       "2          17     2\n",
       "3          17     3\n",
       "4          14     4\n",
       "5           7     5\n",
       "6          13     6\n",
       "7          13     7\n",
       "8          12     8\n",
       "9          14     9\n",
       "10         10    10\n",
       "11         11    11\n",
       "12         12    12\n",
       "13         30    13\n",
       "14         30    14"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer** We estimate the probability of getting heads to be 49% with a 95% CI of (0.45, 0.54). We do not have enough evidence to reject the null hypothesis that the coin is fair. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 part III\n",
    "\n",
    "Generate a histogram of the number of heads from each student. As an extension, include the binomial distribution supported by your estimate that is most amenable to large value outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-88da94077aa146c29a140272d94039d0\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-88da94077aa146c29a140272d94039d0\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-88da94077aa146c29a140272d94039d0\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-3e36b5971c6b02f0d186c5079c3e0618\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"bin\": {\"step\": 1}, \"field\": \"outcome\", \"title\": \"Number of heads\"}, \"y\": {\"type\": \"quantitative\", \"aggregate\": \"count\", \"title\": \"Number of occurences\"}}}, {\"data\": {\"name\": \"data-4613521709c457d01da895383a998db8\"}, \"mark\": {\"type\": \"line\", \"color\": \"firebrick\"}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"value\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"prob\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-3e36b5971c6b02f0d186c5079c3e0618\": [{\"outcome\": 9, \"name\": 0}, {\"outcome\": 13, \"name\": 1}, {\"outcome\": 17, \"name\": 2}, {\"outcome\": 17, \"name\": 3}, {\"outcome\": 14, \"name\": 4}, {\"outcome\": 7, \"name\": 5}, {\"outcome\": 13, \"name\": 6}, {\"outcome\": 13, \"name\": 7}, {\"outcome\": 12, \"name\": 8}, {\"outcome\": 14, \"name\": 9}, {\"outcome\": 10, \"name\": 10}, {\"outcome\": 11, \"name\": 11}, {\"outcome\": 12, \"name\": 12}, {\"outcome\": 30, \"name\": 13}, {\"outcome\": 30, \"name\": 14}], \"data-4613521709c457d01da895383a998db8\": [{\"value\": 0, \"prob\": 1.1450546362065457e-09}, {\"value\": 1, \"prob\": 4.032583718814366e-08}, {\"value\": 2, \"prob\": 6.864158808329565e-07}, {\"value\": 3, \"prob\": 7.520730520430768e-06}, {\"value\": 4, \"prob\": 5.959361466732567e-05}, {\"value\": 5, \"prob\": 0.0003637801521431553}, {\"value\": 6, \"prob\": 0.0017793594398306492}, {\"value\": 7, \"prob\": 0.007161645447268672}, {\"value\": 8, \"prob\": 0.024170553384531807}, {\"value\": 9, \"prob\": 0.06935897927735224}, {\"value\": 10, \"prob\": 0.17098496195764695}, {\"value\": 11, \"prob\": 0.3649481401467555}, {\"value\": 12, \"prob\": 0.6783275213597293}, {\"value\": 13, \"prob\": 1.102565803949264}, {\"value\": 14, \"prob\": 1.5716698882382267}, {\"value\": 15, \"prob\": 1.9680040339678666}, {\"value\": 16, \"prob\": 2.1658740047744187}, {\"value\": 17, \"prob\": 2.093862848605462}, {\"value\": 18, \"prob\": 1.7752315455567964}, {\"value\": 19, \"prob\": 1.3161899788567573}, {\"value\": 20, \"prob\": 0.8498009211314304}, {\"value\": 21, \"prob\": 0.4750439931790591}, {\"value\": 22, \"prob\": 0.22813377538045693}, {\"value\": 23, \"prob\": 0.09315103115723748}, {\"value\": 24, \"prob\": 0.031894103059271685}, {\"value\": 25, \"prob\": 0.00898581686191657}, {\"value\": 26, \"prob\": 0.0020285706962520533}, {\"value\": 27, \"prob\": 0.00035279490369601377}, {\"value\": 28, \"prob\": 4.437327204872156e-05}, {\"value\": 29, \"prob\": 3.592438816538233e-06}, {\"value\": 30, \"prob\": 1.4057369282106098e-07}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig_1_a = (alt\n",
    "           .Chart(head_counts)\n",
    "           .mark_bar()\n",
    "           .encode(alt.X(\"outcome:Q\",\n",
    "                         bin = alt.BinParams(step = 1),\n",
    "                         title = \"Number of heads\"),\n",
    "                   y = alt.Y(\"count()\",\n",
    "                            title = \"Number of occurences\")))\n",
    "\n",
    "k_vals = range(0,31)\n",
    "k_probs = [num_people * stats.binom.pmf(k = k, n = num_flips, p = 0.540) for k in k_vals]\n",
    "binom_dist_df = pd.DataFrame({\"value\": k_vals,\n",
    "                              \"prob\": k_probs})\n",
    "\n",
    "fig_1_b = (alt\n",
    "           .Chart(binom_dist_df)\n",
    "           .mark_line(color= \"firebrick\")\n",
    "           .encode(x = \"value\", \n",
    "                   y = \"prob\"))\n",
    "\n",
    "\n",
    "fig_1_a + fig_1_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binomial distribution with the estimates of probabilities of heads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 part I\n",
    "\n",
    "It looks like there might be a couple of strange points in this dataset as Mittens suspected. Using the upper bound on $p$ calculate the probability of someone getting all heads. Write a couple of sentences explaining whether you think it is reasonable to remove those data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.371579521404065e-09"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.binom.pmf(k = 30, n = 30, p = 0.54)\n",
    "# We have used the upper end of CI to be the most generous\n",
    "# It is highly unlikely that they are generous results -- these are outliers. These are data errors\n",
    "# Part of data science is to remove data that is unreliable from dataset\n",
    "# Very easy to produce results in statistics. Do not take for granted what you see in a dataset\n",
    "# How do you determine outliers to remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 part II\n",
    "\n",
    "Remove the outliers and repeat the process of plotting the data and estimating the parameters and CI. Once you have done this, plot the distribution of the estimated binomial distribution on top of the histogram. Write a couple of sentences explaining what you think about the coin now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4153846153846154, (0.3664761437453554, 0.4642930870238754))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_counts_clean =head_counts.loc[head_counts[\"outcome\"] < 30]\n",
    "\n",
    "total_heads_clean =int(head_counts_clean[\"outcome\"].sum())\n",
    "num_people_clean = int(head_counts_clean[\"name\"].unique().size)\n",
    "\n",
    "wald_estimate_and_ci(num_success=total_heads_clean, num_trials=num_people_clean * num_flips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer** The coin no longer seems to be fair now. The value of the null hypothesis lies outside of the 95% confidence interval. We have enough evidence (at alpha = 0.05) to reject the null hypothesis that the coin is fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-08865c6c2d9c4130b377b24521553237\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-08865c6c2d9c4130b377b24521553237\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-08865c6c2d9c4130b377b24521553237\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-651c4f148c5a2518b55f662c52a2ece8\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"bin\": {\"step\": 1}, \"field\": \"outcome\", \"title\": \"Number of heads\"}, \"y\": {\"type\": \"quantitative\", \"aggregate\": \"count\", \"title\": \"Number of occurences\"}}}, {\"data\": {\"name\": \"data-ab22dc75b6d2ed234cd27ae96f358227\"}, \"mark\": {\"type\": \"line\", \"color\": \"firebrick\"}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"value\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"prob\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-651c4f148c5a2518b55f662c52a2ece8\": [{\"outcome\": 9, \"name\": 0}, {\"outcome\": 13, \"name\": 1}, {\"outcome\": 17, \"name\": 2}, {\"outcome\": 17, \"name\": 3}, {\"outcome\": 14, \"name\": 4}, {\"outcome\": 7, \"name\": 5}, {\"outcome\": 13, \"name\": 6}, {\"outcome\": 13, \"name\": 7}, {\"outcome\": 12, \"name\": 8}, {\"outcome\": 14, \"name\": 9}, {\"outcome\": 10, \"name\": 10}, {\"outcome\": 11, \"name\": 11}, {\"outcome\": 12, \"name\": 12}], \"data-ab22dc75b6d2ed234cd27ae96f358227\": [{\"value\": 0, \"prob\": 1.3446812053531815e-06}, {\"value\": 1, \"prob\": 2.861757437033696e-05}, {\"value\": 2, \"prob\": 0.0002943696645700855}, {\"value\": 3, \"prob\": 0.0019490458702589434}, {\"value\": 4, \"prob\": 0.00933293118643215}, {\"value\": 5, \"prob\": 0.03442814615439438}, {\"value\": 6, \"prob\": 0.10176410722274656}, {\"value\": 7, \"prob\": 0.2475141655527599}, {\"value\": 8, \"prob\": 0.5048125449147636}, {\"value\": 9, \"prob\": 0.8753919344865728}, {\"value\": 10, \"prob\": 1.3041095229146151}, {\"value\": 11, \"prob\": 1.682068226913952}, {\"value\": 12, \"prob\": 1.889331619546509}, {\"value\": 13, \"prob\": 1.8557931884303078}, {\"value\": 14, \"prob\": 1.5986106159188909}, {\"value\": 15, \"prob\": 1.2096609105072862}, {\"value\": 16, \"prob\": 0.804502047853403}, {\"value\": 17, \"prob\": 0.47000069361772845}, {\"value\": 18, \"prob\": 0.24080282450784726}, {\"value\": 19, \"prob\": 0.10789006442186948}, {\"value\": 20, \"prob\": 0.0420955678705843}, {\"value\": 21, \"prob\": 0.014220318002680022}, {\"value\": 22, \"prob\": 0.004126875504274278}, {\"value\": 23, \"prob\": 0.0010183000129461565}, {\"value\": 24, \"prob\": 0.0002106952662114393}, {\"value\": 25, \"prob\": 3.587221968317836e-05}, {\"value\": 26, \"prob\": 4.893810377553899e-06}, {\"value\": 27, \"prob\": 5.143225847888285e-07}, {\"value\": 28, \"prob\": 3.909228437497448e-08}, {\"value\": 29, \"prob\": 1.912560921381039e-09}, {\"value\": 30, \"prob\": 4.522579956542049e-11}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_vals = range(0,31)\n",
    "k_probs = [num_people_clean * stats.binom.pmf(k = k, n = num_flips, p = 0.415) for k in k_vals]\n",
    "binom_dist_df = pd.DataFrame({\"value\": k_vals,\n",
    "                              \"prob\": k_probs})\n",
    "\n",
    "fig_2_a = (alt\n",
    "           .Chart(head_counts_clean)\n",
    "           .mark_bar()\n",
    "           .encode(alt.X(\"outcome:Q\",\n",
    "                         bin = alt.BinParams(step = 1),\n",
    "                         title = \"Number of heads\"),\n",
    "                   y = alt.Y(\"count()\",\n",
    "                            title = \"Number of occurences\")))\n",
    "\n",
    "fig_2_b = (alt\n",
    "           .Chart(binom_dist_df)\n",
    "           .mark_line(color= \"firebrick\")\n",
    "           .encode(x = \"value\", y = \"prob\"))\n",
    "\n",
    "fig_2_a + fig_2_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental results: flipping coins in parallel\n",
    "\n",
    "After the success of his first experiment, Mittens was lauded as a statistical wizard. The royal mint has become interested and is providing additional funds to obtain an additional 49 coins and repeat the experiment to gather more data about the fascinating topic of coin bias. Now he gives each of 50 students a coin each and asks them to flip the coin 30 times and record the results. We will help Mittens work out whether the coins are fair.\n",
    "\n",
    "### Excercise 5 part I\n",
    "\n",
    "Do we need to change anything about how we analyse this data? If so, why, if not, why not? **Hint:** there are good arguments that can be given for each answer. Once you have answered one way, try to answer the other way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "The nature of analysis will depend on whether we are assuming that all coins are equally \"fair\" or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 part II\n",
    "\n",
    "Using the data in `experiment2.csv` explore the data set using the methodology devised above and write a couple of sentences to explain what you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2 = pd.read_csv(\"experiment2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4013333333333333, (0.37652739859779666, 0.42613926806887))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2 = pd.read_csv(\"experiment2.csv\")\n",
    "\n",
    "head_counts = exp2.drop(columns=\"flip_number\").groupby(\"name\").sum()\n",
    "head_counts[\"name\"] = head_counts.index.copy()\n",
    "\n",
    "total_heads = int(head_counts[\"outcome\"].sum())\n",
    "num_people = int(head_counts[\"name\"].unique().size)\n",
    "num_flips = int(exp2[\"name\"].value_counts().unique())\n",
    "\n",
    "wald_estimate = wald_estimate_and_ci(num_success=total_heads, \n",
    "                                     num_trials=num_people * num_flips)\n",
    "\n",
    "print(wald_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "As it stands now, the coins (in aggregate) do not seem to be fair. Under H0, our expected value would be 0.5, but this does not fall in the range of the 95% CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 part III\n",
    "\n",
    "Visualise the number of heads each student got and compare the variance in this to what is predicted by theory. Revise your answer to part I of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.69224489795919 7.2079466666666665\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-80e6292a0dbd46989a4a674f62258cbe\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-80e6292a0dbd46989a4a674f62258cbe\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-80e6292a0dbd46989a4a674f62258cbe\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-6848c08f6b43d814c683ff191c0a1025\"}, \"mark\": \"point\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"name\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"outcome\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-6848c08f6b43d814c683ff191c0a1025\": [{\"outcome\": 7, \"name\": 0}, {\"outcome\": 7, \"name\": 1}, {\"outcome\": 4, \"name\": 2}, {\"outcome\": 7, \"name\": 3}, {\"outcome\": 4, \"name\": 4}, {\"outcome\": 4, \"name\": 5}, {\"outcome\": 10, \"name\": 6}, {\"outcome\": 7, \"name\": 7}, {\"outcome\": 11, \"name\": 8}, {\"outcome\": 3, \"name\": 9}, {\"outcome\": 12, \"name\": 10}, {\"outcome\": 10, \"name\": 11}, {\"outcome\": 12, \"name\": 12}, {\"outcome\": 12, \"name\": 13}, {\"outcome\": 9, \"name\": 14}, {\"outcome\": 14, \"name\": 15}, {\"outcome\": 9, \"name\": 16}, {\"outcome\": 6, \"name\": 17}, {\"outcome\": 9, \"name\": 18}, {\"outcome\": 10, \"name\": 19}, {\"outcome\": 13, \"name\": 20}, {\"outcome\": 15, \"name\": 21}, {\"outcome\": 10, \"name\": 22}, {\"outcome\": 15, \"name\": 23}, {\"outcome\": 12, \"name\": 24}, {\"outcome\": 13, \"name\": 25}, {\"outcome\": 15, \"name\": 26}, {\"outcome\": 15, \"name\": 27}, {\"outcome\": 8, \"name\": 28}, {\"outcome\": 9, \"name\": 29}, {\"outcome\": 13, \"name\": 30}, {\"outcome\": 11, \"name\": 31}, {\"outcome\": 13, \"name\": 32}, {\"outcome\": 13, \"name\": 33}, {\"outcome\": 19, \"name\": 34}, {\"outcome\": 16, \"name\": 35}, {\"outcome\": 20, \"name\": 36}, {\"outcome\": 16, \"name\": 37}, {\"outcome\": 17, \"name\": 38}, {\"outcome\": 11, \"name\": 39}, {\"outcome\": 17, \"name\": 40}, {\"outcome\": 11, \"name\": 41}, {\"outcome\": 16, \"name\": 42}, {\"outcome\": 15, \"name\": 43}, {\"outcome\": 15, \"name\": 44}, {\"outcome\": 18, \"name\": 45}, {\"outcome\": 15, \"name\": 46}, {\"outcome\": 16, \"name\": 47}, {\"outcome\": 18, \"name\": 48}, {\"outcome\": 20, \"name\": 49}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_var = head_counts[\"outcome\"].var()\n",
    "thry_var = stats.binom.var(n = num_flips, p = wald_estimate[0])\n",
    "\n",
    "print(emp_var,thry_var)\n",
    "\n",
    "alt.Chart(head_counts).mark_point().encode(\n",
    "    x = \"name\",\n",
    "    y = \"outcome\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer** \n",
    "The variance of the experimental data is > 2x than that of the theoretical model, which indicates that the coins were likely not all fair to the same extent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 part IV (Extension)\n",
    "\n",
    "Consider how you might analyse this data. Over the following weeks you will learn a couple of approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would basically need to estimate a different probability (p) for each coin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epilogue\n",
    "\n",
    "Professor Mittens' work was published in a top tier journal and he was lauded as a statistical wizard. Rumour has it he will soon be elected to the British Acadmey."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
